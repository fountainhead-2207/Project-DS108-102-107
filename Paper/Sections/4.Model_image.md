# 1 Mô hình

## 1.1 Mô hình đa phương thức

Mục tiêu là dự đoán điểm số hữu ích của hình ảnh sản phẩm (2-5) bằng cách tích
hợp đặc trưng hình ảnh, văn bản, và danh mục. Mô hình sử dụng ResNet50 [**?** ,
]]he2016deep, PhoBERT [**?** , ]]phobert, và mạng nơ-ron kết nối đầy đủ với tối ưu
hóa Adam và hàm mất mát cross-entropy.

**1.1.1 Kiến trúc mô hình**

Mô hình bao gồm ba thành phần chính:

- **ResNet50** : Mô hình CNN với 50 tầng, huấn luyện trước trên ImageNet, trích
    xuất đặc trưng hình ảnh (2048 chiều). Chỉ tinh chỉnh tầnglayer4.
- **PhoBERT** : Biến thể RoBERTa cho tiếng Việt, 12 tầng Transformer, hidden
    size 768, 12 attention heads. Lấy embedding token[CLS](768 chiều) từ tên
    sản phẩm.
- **Mã hóa danh mục** : One-hot encoding cho 5 danh mục (5 chiều).

Các đặc trưng được nối lại (2821 chiều) và đưa vào mạng nơ-ron kết nối đầy
đủ:

- fc1: Linear(2821→256).
- bn1: Batch normalization.
- relu: ReLU activation.
- dropout: Dropout(p=0.6).
- fc2: Linear(256→128).
- bn2: Batch normalization.
- fc3: Linear(128→4).

```
Đầu ra qua softmax:
```
```
pc=
exp(logitsc)
P 4
k=1exp(logitsk)
```
### ,

trong đó logits=W h+b,W∈R^4 ×^128 ,b∈R^4.

```
Table 1: Kiến trúc mạng nơ-ron
Lớp Kích thước đầu vào Kích thước đầu ra
Nối đặc trưng 2048 + 768 + 5 2821
fc1 2821 256
bn1 256 256
relu 256 256
dropout (0.6) 256 256
fc2 256 128
bn2 128 128
fc3 128 4
```
**1.1.2 Tiền xử lý và xây dựng đầu vào**

Quy trình tiền xử lý dữ liệu:

- **Hình ảnh** :
    **-** Resize về 224x224 pixel với padding (LANCZOS resampling).
    **-** Làm mờ Gaussian (bán kính 1).
    **-** Chuẩn hóa: mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225].
    **-** Tăng cường: lật ngang (p=1.0), xoay (-15 đến 15), điều chỉnh độ sáng/tương
       phản (factor=0.3).


- **Văn bản** :
    **-** Tokenization bằngAutoTokenizer.frompretrained(”vinai/phobert−
       base”) :
**-** maxlength= 128, padding=′maxlength′, truncation=T rue.T oattentionmask:
1 chotokenthc, 0 cho[P AD].
**- Danh mục** : Mã hóa one-hot (5 chiều).

```
Gán nhãn : Điểm hữu ích (2-5) ánh xạ sang 0,1,2,3.
Dataset : Đóng góiinputids,
```
```
1.1.3 Hàm mất mát và tối ưu hóa
Hàm mất mát cross-entropy:
```
### LCE=−

### 1

### B

### XB

```
i=
```
### X^4

```
c=
```
```
yi,clogpi,c,
```
```
trong đóyi,clà nhãn one-hot,pi,clà xác suất dự đoán.
Tối ưu hóa:
```
- **Optimizer** : AdamW (learning rate=2e-5, weight decay=5e-4).
- **Scheduler** :ReduceLROnPlateau, giảm learning rate nếu độ chính xác
    kiểm tra không cải thiện sau 2 epoch.
- **Early stopping** : Dừng sau 3 epoch không cải thiện.

```
1.1.4 Thiết lập huấn luyện và đánh giá
```
- **Batch size** : 16 (huấn luyện), 32 (đánh giá).
- **Epochs** : Tối đa 25, dừng sớm nếu cần.
- **Chia dữ liệu** : 80% huấn luyện, 20% kiểm tra, stratified sampling.
- **Metrics** :
    **-** Accuracy: Tỷ lệ dự đoán đúng.
    **-** Macro-F1: Trung bình F1 của các lớp.
    **-** Ma trận nhầm lẫn: Phân phối dự đoán so với nhãn thực.


## 1.2 Quy trình PyTorch

```
Vòng lặp huấn luyện thủ công:
```
- **DataLoader** : Tạo từTensorDatasetvới shuffle cho huấn luyện, không
    shuffle cho kiểm tra.
- **train** epoch() :
- model.train(), tính loss, backpropagate,optimizer.step(),sched-
uler.step(),optimizer.zerograd().
**eval** epoch() :
**model.eval(),torch.no** grad(), thuthpdØon, tnhAccuracyvM acro−F 1.
**Logging & checkpoint** : Lưu mô hình tốt nhất dựa trên Macro-F1.

# 2 Thực nghiệm

## 2.1 Tập dữ liệu

```
Tập dữ liệu bao gồm hình ảnh sản phẩm, tên, danh mục, và điểm hữu ích (2-5), chia
80% huấn luyện, 20% kiểm tra, đảm bảo phân bố nhãn đồng đều.
Kết quả Sau 3 epoch, mô hình đạt:
```
- Accuracy kiểm tra: 91.80% (tăng từ 47.68% sau epoch 1).
- Ma trận nhầm lẫn: Phân biệt tốt một số lớp, nhầm lẫn giữa điểm 3 và 4.

```
