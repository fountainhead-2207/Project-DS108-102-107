5\. Thực nghiệm và kết quả

5\.1. Phần comment của review

5\.1.1. Bộ dữ liệu

Với tổng cộng 15.086 review sản phẩm thu thập từ sàn thương mại điện tử Tiki, chúng tôi thực hiện gán nhãn thủ công 2262 review theo thang đo chỉ số tham khảo của comment (“Comment\_helpfulness” score) từ 1 đến 5. Tiếp theo, nhãn phân lớp được gán như sau:

- **Low (0):** score ≤ 2
- **Mid (1):** score = 3
- **High (2):** score ≥ 4

Phân bố nhãn trên tập gán nhãn:

|Nhãn|Số mẫu|Tỷ lệ (%)|
| :- | :- | :- |
|Low|501|22\.15|
|Mid|829|36\.65|
|High|932|41\.20|

Để đánh giá khả năng tổng quát hóa, chúng tôi chia ngẫu nhiên tập dữ liệu đã gán nhãn thành 80% train (1809 mẫu) và 20% validation (453 mẫu), đảm bảo stratified sampling giữ nguyên tỷ lệ mỗi lớp.

5\.1.2. Thiết lập thí nghiệm

- **Môi trường:** GPU Tesla T4, CUDA 11.2, PyTorch 1.11, Transformers 4.21.
- **Hyperparameters:**
- Learning rate = 2×10⁻⁵
- Batch size = 16 (train), 32 (validation)
- Epochs = 5, early stopping khi không cải thiện macro-F1 sau 2 epoch
- Warm-up = 10% tổng số bước
- Seed = 42
- **Optimizer & Scheduler:** AdamW + Linear decay with warm-up.
- **Baseline so sánh:**
1. **Logistic Regression** trên TF-IDF (unigram + bigram), max\_features=10.000.
1. **LSTM** hai chiều (hidden size=256, 2 layer) với embedding pre-trained FastText tiếng Việt.

5\.1.3. Metrics

Chúng tôi đánh giá model bằng hai metric chính:

·  **Accuracy**: Tỷ lệ dự đoán đúng trên tổng mẫu.

·  **Macro-F1**: Trung bình F1 của ba lớp, đảm bảo đánh giá công bằng với lớp ít mẫu.

5\.1.4. Kết quả và thảo luận

Bảng 1 tổng hợp kết quả của các phương pháp trên tập validation:

![A screenshot of a graph

Description automatically generated](Aspose.Words.9d2fc86e-b830-40df-b216-1c055e483225.001.png)

Bảng 1. Kết quả so sánh trên tập validation.

·  **Logistic Regression** chỉ dùng feature TF-IDF cho kết quả trung bình, do không tận dụng được ngữ nghĩa sâu.

·  **BiLSTM + FastText** cải thiện đáng kể nhờ embedding pre-trained, nhưng vẫn hạn chế khi xử lý ngữ cảnh dài.

·  **PhoBERT-base** vượt trội nhất với Accuracy = 0.83 và Macro-F1 = 0.81, thể hiện khả năng nắm bắt ngữ nghĩa và cú pháp tiếng Việt tốt, đặc biệt với những câu có cấu trúc phức tạp.

Hình 3 minh họa **Confusion Matrix** của PhoBERT trên tập validation, cho thấy:

![](Aspose.Words.9d2fc86e-b830-40df-b216-1c055e483225.002.png)

**Hình 3.** Confusion Matrix trên tập validation của PhoBERT-base

- Mô hình nhận diện tốt lớp **High (2)** với **139/157 mẫu** được phân loại đúng (Recall ≈ 88.5%).
- Lớp **Mid (1)** có 99 mẫu đúng trên tổng 124 (Recall ≈ 79.8%), nhưng có một số bị nhầm sang lớp High (23 mẫu) – cho thấy ranh giới giữa đánh giá “trung bình” và “tốt” có phần mờ.
- Lớp **Low (0)** dễ bị nhầm với Mid, khi có đến 23 mẫu bị phân loại sai (Recall ≈ 60.3%).

Mô hình có xu hướng **“dự đoán thiên về phía trung và cao”**, điều này hợp lý vì trong dữ liệu huấn luyện, các đánh giá có helpfulness cao (4–5 sao) chiếm tỷ lệ lớn hơn. Tuy nhiên, một số lỗi giữa Low và Mid có thể phản ánh sự **mơ hồ trong đánh giá chủ quan của người dùng**, đặc biệt ở ngưỡng 2–3 điểm.



