{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99ed0b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_idx\n",
      "1    444\n",
      "3    326\n",
      "0    252\n",
      "2    124\n",
      "Name: count, dtype: int64\n",
      "Fold 1 E0 F1-macro: 0.3506\n",
      "Fold 1 E1 F1-macro: 0.3173\n",
      "Fold 1 E2 F1-macro: 0.3141\n",
      "Fold 2 E0 F1-macro: 0.3474\n",
      "Fold 2 E1 F1-macro: 0.3330\n",
      "Fold 2 E2 F1-macro: 0.3624\n",
      "Fold 2 E3 F1-macro: 0.3550\n",
      "Fold 2 E4 F1-macro: 0.3765\n",
      "Fold 3 E0 F1-macro: 0.2767\n",
      "Fold 3 E1 F1-macro: 0.2915\n",
      "Fold 3 E2 F1-macro: 0.2968\n",
      "Fold 3 E3 F1-macro: 0.3380\n",
      "Fold 3 E4 F1-macro: 0.3390\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 222\u001b[0m\n\u001b[0;32m    220\u001b[0m results\u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,(tr,va) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(skf\u001b[38;5;241m.\u001b[39msplit(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(dataset)), df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel_idx\u001b[39m\u001b[38;5;124m'\u001b[39m])):\n\u001b[1;32m--> 222\u001b[0m     acc,f1\u001b[38;5;241m=\u001b[39mtrain_fold(tr,va,i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    223\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend((acc,f1))\n\u001b[0;32m    224\u001b[0m \u001b[38;5;66;03m# In kết quả\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[2], line 203\u001b[0m, in \u001b[0;36mtrain_fold\u001b[1;34m(train_idx, val_idx, fold)\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m imgs,ids,mask,rating,cat,labels \u001b[38;5;129;01min\u001b[39;00m val_loader:\n\u001b[0;32m    202\u001b[0m     imgs,ids,mask,rating,cat,labels\u001b[38;5;241m=\u001b[39m[x\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m (imgs,ids,mask,rating,cat,labels)]\n\u001b[1;32m--> 203\u001b[0m     out\u001b[38;5;241m=\u001b[39mmodel(imgs,ids,mask,rating,cat)\n\u001b[0;32m    204\u001b[0m     pred\u001b[38;5;241m=\u001b[39mout\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    205\u001b[0m     preds\u001b[38;5;241m.\u001b[39mextend(pred\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()); trues\u001b[38;5;241m.\u001b[39mextend(labels\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "File \u001b[1;32mc:\\Users\\Sacchi\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Sacchi\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[2], line 159\u001b[0m, in \u001b[0;36mMultiModalModel.forward\u001b[1;34m(self, img, ids, mask, rating, cat)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, img, ids, mask, rating, cat):\n\u001b[0;32m    158\u001b[0m     img_feat\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresnet(img)\n\u001b[1;32m--> 159\u001b[0m     txt_out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbert(input_ids\u001b[38;5;241m=\u001b[39mids, attention_mask\u001b[38;5;241m=\u001b[39mmask)\n\u001b[0;32m    160\u001b[0m     txt_feat\u001b[38;5;241m=\u001b[39mtxt_out\u001b[38;5;241m.\u001b[39mlast_hidden_state[:,\u001b[38;5;241m0\u001b[39m,:]\n\u001b[0;32m    161\u001b[0m     cat_feat\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcat_emb(cat)\n",
      "File \u001b[1;32mc:\\Users\\Sacchi\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Sacchi\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Sacchi\\anaconda3\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:869\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    862\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[0;32m    863\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[0;32m    864\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[0;32m    865\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[0;32m    866\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[0;32m    867\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m--> 869\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[0;32m    870\u001b[0m     embedding_output,\n\u001b[0;32m    871\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mextended_attention_mask,\n\u001b[0;32m    872\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[0;32m    873\u001b[0m     encoder_hidden_states\u001b[38;5;241m=\u001b[39mencoder_hidden_states,\n\u001b[0;32m    874\u001b[0m     encoder_attention_mask\u001b[38;5;241m=\u001b[39mencoder_extended_attention_mask,\n\u001b[0;32m    875\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[0;32m    876\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m    877\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m    878\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m    879\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m    880\u001b[0m )\n\u001b[0;32m    881\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    882\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Sacchi\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Sacchi\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Sacchi\\anaconda3\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:618\u001b[0m, in \u001b[0;36mRobertaEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    607\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    608\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    609\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    615\u001b[0m         output_attentions,\n\u001b[0;32m    616\u001b[0m     )\n\u001b[0;32m    617\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 618\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m layer_module(\n\u001b[0;32m    619\u001b[0m         hidden_states,\n\u001b[0;32m    620\u001b[0m         attention_mask,\n\u001b[0;32m    621\u001b[0m         layer_head_mask,\n\u001b[0;32m    622\u001b[0m         encoder_hidden_states,\n\u001b[0;32m    623\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    624\u001b[0m         past_key_value,\n\u001b[0;32m    625\u001b[0m         output_attentions,\n\u001b[0;32m    626\u001b[0m     )\n\u001b[0;32m    628\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    629\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mc:\\Users\\Sacchi\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Sacchi\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Sacchi\\anaconda3\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:549\u001b[0m, in \u001b[0;36mRobertaLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    546\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    547\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[1;32m--> 549\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m apply_chunking_to_forward(\n\u001b[0;32m    550\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeed_forward_chunk, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_size_feed_forward, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseq_len_dim, attention_output\n\u001b[0;32m    551\u001b[0m )\n\u001b[0;32m    552\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[0;32m    554\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Sacchi\\anaconda3\\Lib\\site-packages\\transformers\\pytorch_utils.py:253\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[1;32m--> 253\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m forward_fn(\u001b[38;5;241m*\u001b[39minput_tensors)\n",
      "File \u001b[1;32mc:\\Users\\Sacchi\\anaconda3\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:562\u001b[0m, in \u001b[0;36mRobertaLayer.feed_forward_chunk\u001b[1;34m(self, attention_output)\u001b[0m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[0;32m    561\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate(attention_output)\n\u001b[1;32m--> 562\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[0;32m    563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[1;32mc:\\Users\\Sacchi\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Sacchi\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Sacchi\\anaconda3\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:473\u001b[0m, in \u001b[0;36mRobertaOutput.forward\u001b[1;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor, input_tensor: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 473\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense(hidden_states)\n\u001b[0;32m    474\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[0;32m    475\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(hidden_states \u001b[38;5;241m+\u001b[39m input_tensor)\n",
      "File \u001b[1;32mc:\\Users\\Sacchi\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Sacchi\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Sacchi\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Notebook: Fine-Tune mô hình ResNet + PhoBERT + Metadata để phân loại image_helpfulness\n",
    "\n",
    "\n",
    "# 1. Cài đặt và import\n",
    "\n",
    "import os, json, requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import transforms, models\n",
    "from transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "## 2. Đọc và tiền xử lý dữ liệu\n",
    "\n",
    "# Đọc JSON\n",
    "data_path = 'all_labeled.json'\n",
    "with open(data_path) as f:\n",
    "    raw = json.load(f)\n",
    "# Chuyển thành DataFrame\n",
    "records=[]\n",
    "for item in raw:\n",
    "    data=item['data']; anns=item.get('annotations',[])\n",
    "    # Lấy nhãn\n",
    "    lbl=None\n",
    "    for ann in anns:\n",
    "        for r in ann['result']:\n",
    "            if r['from_name']=='Image_helpfulness': lbl=int(r['value']['choices'][0])\n",
    "    if lbl is None or lbl<2: continue\n",
    "    imgs=data.get('images',[])\n",
    "    if not imgs: continue\n",
    "    records.append({'url':imgs[0], 'name':data.get('product_name',''),\n",
    "                    'rating':data.get('rating',0),'category':data.get('product_category',''),\n",
    "                    'label':lbl})\n",
    "df=pd.DataFrame(records)\n",
    "# Loại bỏ các bản ghi không có URL hợp lệ\n",
    "df=df[df['url'].apply(lambda x: isinstance(x, str) and x.startswith('http'))]\n",
    "# Chuẩn hóa rating\n",
    "scaler=MinMaxScaler(); df['rating_norm']=scaler.fit_transform(df[['rating']])\n",
    "# Ánh xạ category\n",
    "cats=df['category'].unique().tolist(); cat2idx={c:i for i,c in enumerate(cats)}\n",
    "df['cat_idx']=df['category'].map(cat2idx)\n",
    "# Chuyển nhãn về 0-3\n",
    "df['label_idx']=df['label']-2\n",
    "print(df['label_idx'].value_counts())\n",
    "\n",
    "## 3. Dataset và Transform\n",
    "\n",
    "\n",
    "# Tiết kiệm thời gian: tải trước tất cả ảnh về thư mục local\n",
    "import os\n",
    "os.makedirs('images', exist_ok=True)\n",
    "local_paths = []\n",
    "for idx, url in enumerate(df['url']):\n",
    "    local_file = os.path.join('images', f'image_{idx}.jpg')\n",
    "    if not os.path.exists(local_file):\n",
    "        try:\n",
    "            resp = requests.get(url, timeout=5)\n",
    "            with open(local_file, 'wb') as f:\n",
    "                f.write(resp.content)\n",
    "        except Exception as e:\n",
    "            print(f\"Không tải được {url}: {e}\")\n",
    "    local_paths.append(local_file)\n",
    "# Gán cột path trong DataFrame\n",
    "df['img_path'] = local_paths\n",
    "\n",
    "# Transform ảnh\n",
    "mean=[0.485,0.456,0.406]; std=[0.229,0.224,0.225]\n",
    "transform=transforms.Compose([\n",
    "    transforms.Resize((224,224)), transforms.ToTensor(), transforms.Normalize(mean,std)\n",
    "])\n",
    "# Tokenizer PhoBERT\n",
    "tokenizer=AutoTokenizer.from_pretrained('vinai/phobert-base')\n",
    "# Dataset\n",
    "torch.manual_seed(42)\n",
    "class MultiModalDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df=df.reset_index(drop=True)\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self,i):\n",
    "        row=self.df.iloc[i]\n",
    "        # ảnh: mở từ local file thay vì tải mạng\n",
    "        img = Image.open(row['img_path']).convert('RGB')\n",
    "        img_t = transform(img)\n",
    "        # text\n",
    "        enc = tokenizer(row['name'], padding='max_length', truncation=True,\n",
    "                        max_length=32, return_tensors='pt')\n",
    "        input_ids = enc['input_ids'].squeeze(0)\n",
    "        attn = enc['attention_mask'].squeeze(0)\n",
    "        # metadata\n",
    "        rating = torch.tensor(row['rating_norm'], dtype=torch.float32)\n",
    "        cat = torch.tensor(row['cat_idx'], dtype=torch.long)\n",
    "        label = torch.tensor(row['label_idx'], dtype=torch.long)\n",
    "        return img_t, input_ids, attn, rating, cat, label\n",
    "\n",
    "# Tạo dataset\n",
    "dataset = MultiModalDataset(df)\n",
    "\n",
    "# Transform ảnh\n",
    "mean=[0.485,0.456,0.406]; std=[0.229,0.224,0.225]\n",
    "transform=transforms.Compose([\n",
    "    transforms.Resize((224,224)), transforms.ToTensor(), transforms.Normalize(mean,std)\n",
    "])\n",
    "# Tokenizer PhoBERT\n",
    "tokenizer=AutoTokenizer.from_pretrained('vinai/phobert-base')\n",
    "# Dataset\n",
    "torch.manual_seed(42)\n",
    "class MultiModalDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df=df.reset_index(drop=True)\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self,i):\n",
    "        row=self.df.iloc[i]\n",
    "        # ảnh\n",
    "        resp=requests.get(row['url']); img=Image.open(BytesIO(resp.content)).convert('RGB')\n",
    "        img_t=transform(img)\n",
    "        # text\n",
    "        enc=tokenizer(row['name'],padding='max_length',truncation=True,\n",
    "                       max_length=32,return_tensors='pt')\n",
    "        input_ids=enc['input_ids'].squeeze(0)\n",
    "        attn=enc['attention_mask'].squeeze(0)\n",
    "        # metadata\n",
    "        rating=torch.tensor(row['rating_norm'],dtype=torch.float32)\n",
    "        cat=torch.tensor(row['cat_idx'],dtype=torch.long)\n",
    "        label=torch.tensor(row['label_idx'],dtype=torch.long)\n",
    "        return img_t, input_ids, attn, rating, cat, label\n",
    "\n",
    "dataset=MultiModalDataset(df)\n",
    "\n",
    "## 4. Mô hình đa phương thức\n",
    "\n",
    "class MultiModalModel(nn.Module):\n",
    "    def __init__(self, num_categories, embed_dim=8, num_classes=4):\n",
    "        super().__init__()\n",
    "        # ResNet50\n",
    "        w=models.ResNet50_Weights.DEFAULT\n",
    "        self.resnet=models.resnet50(weights=w)\n",
    "        self.resnet.fc=nn.Identity()\n",
    "        # BERT\n",
    "        self.bert=AutoModel.from_pretrained('vinai/phobert-base')\n",
    "        # Embedding cho category\n",
    "        self.cat_emb=nn.Embedding(num_categories, embed_dim)\n",
    "        # FC layers\n",
    "        dim_img=2048; dim_txt=768\n",
    "        self.fc1=nn.Linear(dim_img+dim_txt+embed_dim+1,256)\n",
    "        self.drop=nn.Dropout(0.3)\n",
    "        self.fc2=nn.Linear(256,num_classes)\n",
    "    def forward(self, img, ids, mask, rating, cat):\n",
    "        img_feat=self.resnet(img)\n",
    "        txt_out=self.bert(input_ids=ids, attention_mask=mask)\n",
    "        txt_feat=txt_out.last_hidden_state[:,0,:]\n",
    "        cat_feat=self.cat_emb(cat)\n",
    "        r_feat=rating.unsqueeze(1)\n",
    "        x=torch.cat((img_feat,txt_feat,cat_feat,r_feat),dim=1)\n",
    "        x=F.relu(self.fc1(x)); x=self.drop(x)\n",
    "        return self.fc2(x)\n",
    "\n",
    "## 5. Fine-tuning: huấn luyện với Stratified K-Fold, scheduler và EarlyStopping\n",
    "\n",
    "def train_fold(train_idx,val_idx,fold):\n",
    "    # Subset & Dataloader\n",
    "    train_ds, val_ds = Subset(dataset, train_idx), Subset(dataset, val_idx)\n",
    "    train_loader=DataLoader(train_ds,batch_size=16,shuffle=True)\n",
    "    val_loader=DataLoader(val_ds,batch_size=16)\n",
    "    # Model & device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model=MultiModalModel(num_categories=len(cats)).to(device)\n",
    "    # Weighted loss\n",
    "    y_train=[df.iloc[i]['label_idx'] for i in train_idx]\n",
    "    cw=compute_class_weight('balanced', classes=np.arange(4), y=y_train)\n",
    "    weights=torch.tensor(cw,dtype=torch.float32).to(device)\n",
    "    criterion=nn.CrossEntropyLoss(weight=weights)\n",
    "    # Optimizer & scheduler\n",
    "    optimizer=optim.AdamW(model.parameters(),lr=2e-5)\n",
    "    total_steps=len(train_loader)*5\n",
    "    scheduler=get_linear_schedule_with_warmup(optimizer, num_warmup_steps=total_steps//10,\n",
    "                                             num_training_steps=total_steps)\n",
    "    # EarlyStopping params\n",
    "    best_f1=0; patience=2; wait=0\n",
    "    for epoch in range(5):\n",
    "        # train\n",
    "        model.train();\n",
    "        for imgs,ids,mask,rating,cat,labels in train_loader:\n",
    "            imgs,ids,mask,rating,cat,labels=[x.to(device) for x in (imgs,ids,mask,rating,cat,labels)]\n",
    "            optimizer.zero_grad()\n",
    "            out=model(imgs,ids,mask,rating,cat)\n",
    "            loss=criterion(out,labels)\n",
    "            loss.backward(); optimizer.step(); scheduler.step()\n",
    "        # validate\n",
    "        model.eval(); preds=[]; trues=[]\n",
    "        with torch.no_grad():\n",
    "            for imgs,ids,mask,rating,cat,labels in val_loader:\n",
    "                imgs,ids,mask,rating,cat,labels=[x.to(device) for x in (imgs,ids,mask,rating,cat,labels)]\n",
    "                out=model(imgs,ids,mask,rating,cat)\n",
    "                pred=out.argmax(dim=1)\n",
    "                preds.extend(pred.cpu().numpy()); trues.extend(labels.cpu().numpy())\n",
    "        f1=f1_score(trues,preds,average='macro')\n",
    "        print(f\"Fold {fold} E{epoch} F1-macro: {f1:.4f}\")\n",
    "        # EarlyStopping\n",
    "        if f1>best_f1: best_f1, wait= f1, 0; best_model=model.state_dict()\n",
    "        else: wait+=1\n",
    "        if wait>=patience: break\n",
    "    # load best\n",
    "    model.load_state_dict(best_model)\n",
    "    # final eval\n",
    "    acc=accuracy_score(trues,preds); f1m=f1_score(trues,preds,average='macro')\n",
    "    return acc, f1m\n",
    "\n",
    "# Stratified K-Fold\n",
    "skf=StratifiedKFold(n_splits=5,shuffle=True,random_state=42)\n",
    "results=[]\n",
    "for i,(tr,va) in enumerate(skf.split(np.arange(len(dataset)), df['label_idx'])):\n",
    "    acc,f1=train_fold(tr,va,i+1)\n",
    "    results.append((acc,f1))\n",
    "# In kết quả\n",
    "accs, f1s = zip(*results)\n",
    "print(\"Mean Acc:\", np.mean(accs), \"+/-\", np.std(accs))\n",
    "\n",
    "## 6. Lưu mô hình\n",
    "\n",
    "torch.save(best_model, 'best_multimodal_model.pth')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
